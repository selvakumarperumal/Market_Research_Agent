{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e097da93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"./.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36309ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_settings import BaseSettings\n",
    "\n",
    "class LLMConfig(BaseSettings):\n",
    "    hf_token: str\n",
    "    model_name: str = \"microsoft/DialoGPT-medium\"\n",
    "    provider: str = \"huggingface_hub\"\n",
    "    temperature: float = 0.1\n",
    "\n",
    "class EmbeddingConfig(BaseSettings):\n",
    "    embedding_model_name: str\n",
    "    gemini_api_key: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1af5245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.chat_models import ChatHuggingFace\n",
    "from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain_chroma.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a840588",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(GoogleGenerativeAIEmbeddings):\n",
    "    def __init__(self, config: EmbeddingConfig):\n",
    "        super().__init__(\n",
    "            google_api_key=config.gemini_api_key,\n",
    "            model=config.embedding_model_name\n",
    "        )\n",
    "\n",
    "class LLM(ChatHuggingFace):\n",
    "    def __init__(self, config: LLMConfig):\n",
    "        endpoint = HuggingFaceEndpoint(\n",
    "            repo_id=config.model_name,\n",
    "            huggingfacehub_api_token=config.hf_token,\n",
    "            temperature=config.temperature,\n",
    "            provider=config.provider\n",
    "        )\n",
    "        super().__init__(llm=endpoint)\n",
    "\n",
    "class VectorStore(Chroma):\n",
    "    def __init__(self, embedding: Embeddings, persist_directory: str, **kwargs):\n",
    "        super().__init__(embedding_function=embedding, persist_directory=persist_directory, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bec29e",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "STATE DEFINITION\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d415082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Any, Dict, Optional\n",
    "\n",
    "class MarketResearchAgentState(BaseModel):\n",
    "    \"\"\"State Object that flow through the entire chain\"\"\"\n",
    "\n",
    "    # Input\n",
    "    file_path: Optional[str] = Field(..., description=\"Path of the file to be processed\")\n",
    "\n",
    "    # OCR / File Reading\n",
    "    min_text_length: Optional[int] = Field(None, description=\"Minimum text length to consider a page valid\")\n",
    "\n",
    "    # Processing\n",
    "    raw_text: Optional[str] = Field(None, description=\"Raw text extracted from the file\")\n",
    "    cleaned_text: Optional[str] = Field(None, description=\"Cleaned text after preprocessing\")\n",
    "    chunks: Optional[List[str]] = Field(None, description=\"List of text chunks for processing\")\n",
    "    embeddings: Optional[List[List[float]]] = Field(None, description=\"Embeddings for each text chunk\")\n",
    "\n",
    "    # retieval\n",
    "    retriever: Optional[Any] = Field(None, description=\"Retriever object for vector store\")\n",
    "\n",
    "    # Retrieval & Analysis\n",
    "    query: Optional[str] = Field(None, description=\"User query for market research\")\n",
    "    query_results: Optional[str] = Field(None, description=\"Results retrieved from vector store\")\n",
    "    competitors: Optional[List[str]] = Field(None, description=\"List of identified competitors\")\n",
    "    profiles: Optional[List[Dict[str, Any]]] = Field(None, description=\"Detailed profiles of competitors\")\n",
    "    scores: Optional[Dict[str, float]] = Field(None, description=\"Scores for each competitor based on analysis\")\n",
    "\n",
    "    # Output\n",
    "    executive_summary: Optional[str] = Field(None, description=\"Executive summary of the market research\")\n",
    "\n",
    "    # Error Handling\n",
    "    error: Optional[str] = Field(None, description=\"Error message if any step fails\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b75d4e",
   "metadata": {},
   "source": [
    "\"\"\"INGESTION NODES\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39bd141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import re\n",
    "\n",
    "def ingest_file(state: MarketResearchAgentState) -> MarketResearchAgentState:\n",
    "    \"\"\"\n",
    "    Ingest the file and update the state with raw text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the PDF document\n",
    "        doc = pymupdf.open(state.file_path)\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "        doc.close()\n",
    "        \n",
    "        # If text extraction failed or text is too short, use OCR\n",
    "        if not text or (state.min_text_length and len(text) < state.min_text_length):\n",
    "            images = convert_from_path(state.file_path)\n",
    "            text = \"\"\n",
    "            for image in images:\n",
    "                text += pytesseract.image_to_string(image)\n",
    "                \n",
    "    except Exception as e:\n",
    "        # Fallback to OCR if PDF reading fails\n",
    "        images = convert_from_path(state.file_path)\n",
    "        text = \"\"\n",
    "        for image in images:\n",
    "            text += pytesseract.image_to_string(image)\n",
    "\n",
    "    state.raw_text = text\n",
    "    return state\n",
    "\n",
    "def clean_text(state: MarketResearchAgentState) -> MarketResearchAgentState:\n",
    "    \"\"\"\n",
    "    Clean the raw text and update the state with cleaned text.\n",
    "    \"\"\"\n",
    "    text = state.raw_text\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    state.cleaned_text = text.strip()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c37490d",
   "metadata": {},
   "source": [
    "\"\"\"Chunk & Embedding\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3752f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "def chunk_text(state: MarketResearchAgentState, chunk_size=1000, chunk_overlap=200) -> MarketResearchAgentState:\n",
    "    \"\"\"\n",
    "    Chunk the cleaned text and update the state with text chunks.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    state.chunks = text_splitter.split_text(state.cleaned_text)\n",
    "    return state\n",
    "\n",
    "def store_embeddings(state: MarketResearchAgentState) -> MarketResearchAgentState:\n",
    "    \"\"\"\n",
    "    Generate embeddings for the text chunks and store them in a vector store.\n",
    "    \"\"\"\n",
    "    embedding_config = EmbeddingConfig()\n",
    "    embeddings = Embeddings(embedding_config)\n",
    "    vector_store = VectorStore(embedding=embeddings, persist_directory=\"./vector_store\")\n",
    "    vector_store.add_texts(state.chunks)\n",
    "    state.retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 20})\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c66acb",
   "metadata": {},
   "source": [
    "\"\"\"LLM Analysis Node\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3bc8c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_core.retrievers import BaseRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd54b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_query_results(state: MarketResearchAgentState) -> MarketResearchAgentState:\n",
    "    \"\"\"\n",
    "    Retrieve relevant documents from the vector store based on the user query.\n",
    "    \"\"\"\n",
    "    if state.retriever is None:\n",
    "        raise ValueError(\"Retriever is not initialized. Please run the embedding storage step first.\")\n",
    "    \n",
    "    docs = state.retriever.invoke(state.query)\n",
    "    state.query_results = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    return state\n",
    "\n",
    "def competitor_detection(query_results: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Detect competitors from the query results and update the state.\n",
    "    \"\"\"\n",
    "    llm_config = LLMConfig()\n",
    "    llm = LLM(llm_config)\n",
    "\n",
    "    system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "        \"You are an expert market research analyst. Your task is to identify competitors from the provided information.\"\n",
    "    )\n",
    "\n",
    "    human_prompt = HumanMessagePromptTemplate.from_template(\n",
    "        \"\"\"Based on the following information, identify and list the competitors:\\n\\n{query_results}\\n\\nList the competitors in a comma-separated format.\n",
    "        Output format:\n",
    "        [\"Competitor1\", \"Competitor2\", ...]\n",
    "        {error}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "\n",
    "    LCEL = (prompt | llm)\n",
    "\n",
    "    error = \"\"\n",
    "    max_retries = 3\n",
    "    retries = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response = LCEL.invoke({\"query_results\": query_results, \"error\": error})\n",
    "            competitors = eval(response.content)\n",
    "            if isinstance(competitors, list):\n",
    "                return competitors\n",
    "            else:\n",
    "                raise ValueError(\"Response is not a list\")\n",
    "        except Exception as e:\n",
    "            error = str(e)\n",
    "            retries += 1\n",
    "            if retries >= max_retries:\n",
    "                raise e\n",
    "            continue\n",
    "\n",
    "def competitor_detection_node(state: MarketResearchAgentState) -> MarketResearchAgentState:\n",
    "    \"\"\"\n",
    "    Detect competitors from the query results and update the state.\n",
    "    \"\"\"\n",
    "    state.competitors = competitor_detection(state.query_results)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c36fd1",
   "metadata": {},
   "source": [
    "\"\"\"Testing Compititor Detection\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f601b766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor Detection Test\n",
      "['Competitor A', 'Competitor B', 'Competitor C', 'Competitor D']\n"
     ]
    }
   ],
   "source": [
    "query_results = \"\"\"Competitor A is a leading provider of AI solutions, offering a range of products from chatbots to data analytics. Competitor B specializes in cloud computing services, providing scalable infrastructure for businesses of all sizes. Competitor C focuses on cybersecurity, delivering advanced threat detection and prevention systems. Competitor D is known for its innovative software development tools that enhance productivity and collaboration among teams.\"\"\"\n",
    "\n",
    "competitor = competitor_detection(query_results)\n",
    "\n",
    "print(\"Competitor Detection Test\")\n",
    "print(competitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f9aba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def competitor_profile_extraction(state: MarketResearchAgentState) -> MarketResearchAgentState:\n",
    "    \"\"\"\n",
    "    Extract detailed profiles for each competitor and update the state.\n",
    "    \"\"\"\n",
    "    llm_config = LLMConfig()\n",
    "    llm = LLM(llm_config)\n",
    "\n",
    "    system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "        \"You are an expert market research analyst. Your task is to create detailed profiles for each competitor based on the provided information.\"\n",
    "    )\n",
    "\n",
    "    human_prompt = HumanMessagePromptTemplate.from_template(\n",
    "        \"\"\"Based on the following information, create a detailed profile for each competitor:\\n\\n{query_results}\\n\\nCompetitors: {competitors}\\n\\nFor each competitor, provide a profile including their strengths, weaknesses, market position, and any other relevant details.\n",
    "        remember it's not json\n",
    "        {error}\n",
    "        Output format:\n",
    "        [\n",
    "            {{\n",
    "                \"name\": \"Competitor1\",\n",
    "                \"profile\": \"Detailed profile of Competitor1\"\n",
    "            }},\n",
    "            {{\n",
    "                \"name\": \"Competitor2\",\n",
    "                \"profile\": \"Detailed profile of Competitor2\"\n",
    "            }},\n",
    "            ...\n",
    "        ]\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "\n",
    "    LCEL = (prompt | llm)\n",
    "\n",
    "    error = \"\"\n",
    "    max_retries = 3\n",
    "    retries = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response = LCEL.invoke({\"query_results\": state.query_results, \"competitors\": state.competitors, \"error\": error})\n",
    "            print(response.content)\n",
    "            profiles = eval(response.content)\n",
    "            if isinstance(profiles, list):\n",
    "                state.profiles = profiles\n",
    "                return state\n",
    "            else:\n",
    "                raise ValueError(\"Response is not a list\")\n",
    "        except Exception as e:\n",
    "            error = str(e)\n",
    "            retries += 1\n",
    "            if retries >= max_retries:\n",
    "                raise e\n",
    "            continue\n",
    "\n",
    "def score_competitors(state: MarketResearchAgentState) -> MarketResearchAgentState:\n",
    "    \"\"\"\n",
    "    Score each competitor based on their profiles and update the state.\n",
    "    \"\"\"\n",
    "    llm_config = LLMConfig()\n",
    "    llm = LLM(llm_config)\n",
    "\n",
    "    system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "        \"You are an expert market research analyst. Your task is to score each competitor based on their profiles.\"\n",
    "    )\n",
    "\n",
    "    human_prompt = HumanMessagePromptTemplate.from_template(\n",
    "        \"\"\"Based on the following competitor profiles, assign a score to each competitor on a scale of 1 to 10, where 10 indicates the strongest market position:\\n\\n{profiles}\\n\\nProvide the scores in a dictionary format where keys are competitor names and values are their respective scores.\n",
    "        remember it's not json\n",
    "        Output format:\n",
    "        {{\n",
    "            \"Competitor1\": score1,\n",
    "            \"Competitor2\": score2,\n",
    "            ...\n",
    "        }}\n",
    "        {error}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "\n",
    "    LCEL = (prompt | llm)\n",
    "\n",
    "    error = \"\"\n",
    "    max_retries = 3\n",
    "    retries = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response = LCEL.invoke({\"profiles\": state.profiles, \"error\": error})\n",
    "            scores = eval(response.content)\n",
    "            if isinstance(scores, dict):\n",
    "                state.scores = scores\n",
    "                return state\n",
    "            else:\n",
    "                raise ValueError(\"Response is not a dictionary\")\n",
    "        except Exception as e:\n",
    "            error = str(e)\n",
    "            retries += 1\n",
    "            if retries >= max_retries:\n",
    "                raise e\n",
    "            continue\n",
    "\n",
    "def generate_executive_summary(state: MarketResearchAgentState) -> MarketResearchAgentState:\n",
    "    \"\"\"\n",
    "    Generate an executive summary based on the competitor profiles and scores, and update the state.\n",
    "    \"\"\"\n",
    "    llm_config = LLMConfig()\n",
    "    llm = LLM(llm_config)\n",
    "\n",
    "    system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "        \"You are an expert market research analyst. Your task is to generate an executive summary based on the competitor profiles and scores.\"\n",
    "    )\n",
    "\n",
    "    human_prompt = HumanMessagePromptTemplate.from_template(\n",
    "        \"\"\"Based on the following competitor profiles and their scores, generate a concise executive summary highlighting key insights and recommendations:\\n\\nProfiles: {profiles}\\n\\nScores: {scores}\\n\\nThe summary should be clear, informative, and actionable.\n",
    "        {error}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "\n",
    "    LCEL = (prompt | llm)\n",
    "\n",
    "    error = \"\"\n",
    "    max_retries = 3\n",
    "    retries = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response = LCEL.invoke({\"profiles\": state.profiles, \"scores\": state.scores, \"error\": error})\n",
    "            state.executive_summary = response.content\n",
    "            return state\n",
    "        except Exception as e:\n",
    "            error = str(e)\n",
    "            retries += 1\n",
    "            if retries >= max_retries:\n",
    "                raise e\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d5bb307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "047e513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_market_research_agent_graph() -> StateGraph:\n",
    "    graph = StateGraph(MarketResearchAgentState)\n",
    "\n",
    "    graph.add_node(\"IngestFile\", action=ingest_file)\n",
    "    graph.add_node(\"CleanText\", action=clean_text)\n",
    "    graph.add_node(\"ChunkText\", action=chunk_text)\n",
    "    graph.add_node(\"StoreEmbeddings\", action=store_embeddings)\n",
    "    graph.add_node(\"RetrieveQueryResults\", action=retrieve_query_results)\n",
    "    graph.add_node(\"CompetitorDetection\", action=competitor_detection_node)\n",
    "    graph.add_node(\"CompetitorProfileExtraction\", action=competitor_profile_extraction)\n",
    "    graph.add_node(\"ScoreCompetitors\", action=score_competitors)\n",
    "    graph.add_node(\"GenerateExecutiveSummary\", action=generate_executive_summary)\n",
    "\n",
    "    graph.add_edge(START, \"IngestFile\")\n",
    "    graph.add_edge(\"IngestFile\", \"CleanText\")\n",
    "    graph.add_edge(\"CleanText\", \"ChunkText\")\n",
    "    graph.add_edge(\"ChunkText\", \"StoreEmbeddings\")\n",
    "    graph.add_edge(\"StoreEmbeddings\", \"RetrieveQueryResults\")\n",
    "    graph.add_edge(\"RetrieveQueryResults\", \"CompetitorDetection\")\n",
    "    graph.add_edge(\"CompetitorDetection\", \"CompetitorProfileExtraction\")\n",
    "    graph.add_edge(\"CompetitorProfileExtraction\", \"ScoreCompetitors\")\n",
    "    graph.add_edge(\"ScoreCompetitors\", \"GenerateExecutiveSummary\")\n",
    "    graph.add_edge(\"GenerateExecutiveSummary\", END)\n",
    "\n",
    "    return graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fad78395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    initial_state = MarketResearchAgentState(\n",
    "        file_path=\"/home/selva/Documents/langchain-projects/Market_Research_Agent/industry_report_detailed.pdf\",\n",
    "        min_text_length=1000,\n",
    "        query=\"Identify key competitors in the EV market\"\n",
    "    )\n",
    "    graph = build_market_research_agent_graph().invoke(initial_state)\n",
    "    print(\"Executive Summary:\")\n",
    "    print(graph['executive_summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f88656c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"name\": \"CATL\",\n",
      "        \"profile\": \"CATL (Contemporary Amperex Technology Co. Limited) is the global market leader in EV batteries with a dominant 35% market share. Headquartered in China, the company benefits from strong manufacturing scale and cost advantages. Its key strengths include being the world's largest battery supplier, established production presence in Europe, and extensive R&D capabilities. However, CATL faces weaknesses such as geopolitical risks due to its China-centric operations and potential supply chain vulnerabilities. The company maintains its market position through technological innovation and strategic partnerships with major automakers worldwide.\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"LG Energy Solution\",\n",
      "        \"profile\": \"LG Energy Solution holds the second-largest market position with 20% global market share. The South Korean company specializes in high-nickel battery chemistries, offering superior energy density for premium electric vehicles. Its strengths include advanced technological expertise, strong automotive partnerships, and global manufacturing footprint. Weaknesses include higher production costs compared to LFP alternatives and dependence on nickel supply chains. The company focuses on maintaining its technological edge while expanding production capacity to meet growing EV demand.\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Panasonic\",\n",
      "        \"profile\": \"Panasonic maintains a strong 15% market share, largely driven by its exclusive partnership with Tesla. The Japanese company leverages decades of battery manufacturing experience and quality reputation. Key strengths include reliable product quality, strong Tesla relationship, and solid-state battery research investments. Weaknesses include over-reliance on a single major customer and slower expansion compared to Chinese competitors. Panasonic's market position is secured through technological excellence and strategic alliances, though it faces pressure to diversify its customer base.\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"BYD\",\n",
      "        \"profile\": \"BYD Company Limited holds 10% market share with rapid growth driven by vertical integration. The Chinese manufacturer uniquely combines battery production with electric vehicle manufacturing, creating synergies across its business. Strengths include complete vertical integration, cost-effective LFP technology, and expanding global presence. Weaknesses include perceived quality issues in international markets and geopolitical challenges. BYD's market position is strengthened by its ability to control the entire supply chain from raw materials to finished vehicles.\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Samsung SDI\",\n",
      "        \"profile\": \"Samsung SDI holds a 7% market share with a focus on next-generation battery technologies. The South Korean company is making significant investments in solid-state battery development and premium battery solutions. Strengths include strong R&D capabilities, Samsung Group backing, and high-quality product reputation. Weaknesses include smaller scale compared to market leaders and higher price positioning. The company's strategy focuses on technological differentiation and targeting premium automotive segments with advanced battery solutions.\"\n",
      "    }\n",
      "]\n",
      "Executive Summary:\n",
      "### Executive Summary: EV Battery Market Competitive Landscape\n",
      "\n",
      "**Overview**  \n",
      "The global EV battery market is dominated by five key players, with CATL leading at a 35% market share and a perfect score of 10.0, followed by LG Energy Solution (20% share, score 9.0), Panasonic (15% share, score 8.0), BYD (10% share, score 7.0), and Samsung SDI (7% share, score 6.0). The scores reflect a combination of market position, technological capabilities, and strategic strengths, with Chinese and South Korean firms holding the top positions.\n",
      "\n",
      "**Key Insights**  \n",
      "1. **Market Leadership**: CATL’s dominance is driven by scale, cost advantages, and global partnerships, but it faces geopolitical and supply chain risks.  \n",
      "2. **Technology Differentiation**: LG Energy Solution and Samsung SDI excel in high-nickel and solid-state technologies, targeting premium segments, though they contend with cost and scalability challenges.  \n",
      "3. **Strategic Dependencies**: Panasonic’s reliance on Tesla is a strength but also a vulnerability, highlighting the need for customer diversification.  \n",
      "4. **Vertical Integration**: BYD’s integrated model provides cost and supply chain control but is hindered by quality perceptions and geopolitical headwinds.  \n",
      "5. **Innovation Focus**: All players are investing in R&D (e.g., solid-state batteries), with scores correlating to their ability to balance innovation, scale, and risk.\n",
      "\n",
      "**Recommendations**  \n",
      "- **For Competitors**: Diversify supply chains and customer bases to mitigate geopolitical and single-client risks (e.g., Panasonic).  \n",
      "- **For Investors/Policymakers**: Prioritize partnerships with firms demonstrating robust R&D and global expansion plans (e.g., CATL, LG Energy Solution).  \n",
      "- **For Market Entrants**: Focus on niche technologies (e.g., solid-state) to compete against scale-driven leaders, while addressing cost and quality gaps.  \n",
      "\n",
      "This landscape underscores the criticality of innovation, strategic alliances, and risk management in maintaining competitive advantage. Actions should emphasize agility and long-term technological investments.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend_api (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
